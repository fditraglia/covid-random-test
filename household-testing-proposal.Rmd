---
title: "A Short Note on Surveillance Testing"
author: "FD, CG, VK & NQ on behalf of LMH Governing Body"
date: "14/09/2020"
fontsize: 12pt
output: pdf_document
urlcolor: blue
fig_caption: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Controlling the spread of coronavirus infection within the university requires a reliable means of detecting clusters of infection. Guiding future policy changes, e.g. restricting in-person instruction, demands accurate information about the prevalence of infection.
This document outlines some simple strategies to achieve both goals. We focus on detecting the presence of infection among *household groups* of students in college or university-provided residential accommodation. We restrict attention to students rather than the university community as a whole because, given limited testing and logistical capacity, it makes sense to focus on the sub-population in which transmission is most likely to occur. We treat household groups, rather than individual students, as our unit of analysis for two reasons: first because this allows us to employ a simple and efficient pooled testing strategy, and second because it is transmission *between* rather than within households that is of more serious concern. The problem of estimating infection prevalence among households and detecting clusters of infection is fundamentally different from that of determining whether a particular individual has the coronavirus. In particular, the high test specificity and sensitivity along with rapid turnaround that are crucial for individual medical diagnosis are not absolutely essential for surveillance testing. Our calculations suggest that relatively modest resources may be sufficient to obtain valuable information, separate from and parallel to the "Early Alert Testing" service. The ideas we discuss are neither novel nor original, and we do not propose a detailed plan for surveillance testing. Our goals are primarily to explain randomized and pooled testing strategies to a non-specialist audience, and to calculate the approximate scale of testing required. We begin by abstracting away the problem of false negatives and false positives. The final section discusses how these affect our analysis.

## The Bottom Line
```{r, echo=FALSE}
get_pool_fraction <- function(pool_size, prob_positive) {
  1 / pool_size + 1 - (1 - prob_positive)^pool_size
}
get_optimal_pool <- function(prob_positive) {
  k <- 1:100
  k[which.min(get_pool_fraction(k, prob_positive))]
}
get_optimal_pool_fraction <- function(prob_positive) {
  k <- get_optimal_pool(prob_positive)
  get_pool_fraction(k, prob_positive)
}
get_pool_tests <- function(n, pool_size, prob_positive) {
  round(n * get_pool_fraction(pool_size, prob_positive))
}
```

We view a policy of universal pooled testing, like that planned by the University of Cambridge, as the first-best policy for identifying clusters of infection and understanding changes in coronavirus prevalence among our students. Sufficient laboratory capacity for roughly 1500 tests per week would allow fortnightly universal testing of students in residential accommodation, pooling tests by household group. Because capacity cannot be diverted from the Early Alert Testing service, the university would need to obtain around 12,000 tests from an alternative source over the course of MT. These need not have a rapid turnaround time: a delay of several days would still allow us to assess the spread of infection. If insufficient laboratory capacity is available for a policy of universal testing, randomized testing on the scale of around 250 tests per week (2000 over the course of the term) could provide valuable information about changes in prevalence and, combined with an adaptive sampling scheme, help us to identify clusters of infection as they emerge. 

## Pooled Testing By Household

Pooled testing is a procedure that can be helpful in situations where laboratory capacity, rather than the ability to collect test samples, is the limiting factor in expanding testing. In this procedure, a single laboratory test is carried out on the *combined* samples of a group of individuals. For a sufficiently accurate test, a negative result for the pooled sample indicates that no one in the group is infected while a positive result indicates that at least one person in the group is infected. Traditionally, a positive group test result would be followed by further testing to determine which individual or individuals in the group is infected. If, however, we are only interested in detecting infected *groups*, then no further testing is required. This makes pooled testing an extremely efficient procedure when applied to household groups: only one test is required to determine whether any members of a given household are infected with coronavirus. Given that household members would be required to isolate if any of them tested positive, for the purposes of reducing the spread of infection it is irrelevant precisely which of them is infected.

There are approximately 24,000 students at the University of Oxford divided roughly evenly between undergraduate and graduate students.[^studentN] As a rough approximation, suppose that 100\% of undergraduates and roughly 50\% of graduate students are housed in college or university--provided accommodation. With a household size of 6, this makes 3000 households in total. Accordingly, sufficient laboratory capacity for 1500 tests per week would allow fortnightly universal surveillance testing, pooling tests by household. Pooled testing reduces the number of laboratory tests required but does not affect the number of samples that need to be collected. To reduce the burden of collecting samples from approximately 200 students daily, swabs could be self-administered under the guidance of a healthcare professional.[^1] 

[^studentN]: For precise student numbers, see <https://www.ox.ac.uk/about/facts-and-figures/student-numbers>.

We view universal pooled testing of households as the first-best policy for understanding and controlling the spread of infection. Should there be insufficient testing capacity to implement such a policy, however, there are alternative strategies that can provide valuable information with fewer resources. The remainder of this document explains some simple and effective possibilities. 

[^1]: This is the procedure used by the ONS in their [Coronavirus Infection Survey pilot](https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/bulletins/coronaviruscovid19infectionsurveypilot/11september2020). A recent study suggests that this procedure is no less accurate than having healthcare workers conduct the swabs directly: <https://www.medrxiv.org/content/10.1101/2020.04.11.20062372v1>.



## Random Sampling of Households

Suppose that $C$ of the roughly 3000 households in the university contain at least one member who is infected with coronavirus. With a perfect test, we could learn $C$ exactly with 3000 tests, pooling by household. But what if we only have the capacity to carry out $n$ tests, where $n$ is much smaller than 3000? In this case we cannot learn $C$ exactly, but by employing *randomized testing* we can produce an estimate that is sufficiently accurate to guide our mitigation policies and help us to identify clusters of infection. The value of randomized testing is widely acknowledged. It underlies both the [Coronavirus Infection Survey pilot](https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/bulletins/coronaviruscovid19infectionsurveypilot/11september2020) conducted by the ONS, and the [REACT-1](https://www.gov.uk/government/publications/react-1-study-of-coronavirus-transmission-august-2020-results/react-1-real-time-assessment-of-community-transmission-of-coronavirus-covid-19-in-august-2020) survey conducted by the Department of Health and Social Care. Both of these surveys are extremely valuable, but as they aim to be nationally representative, neither employs a sufficiently large sample size to track local trends. As such we propose that randomized surveillance testing be carried out within the university.

The most basic form of randomized testing relies on a *simple random sample*. To use this procedure, we assign each household an id number, place all 3000 id numbers into a hat, mix them up thoroughly, and then draw out $n$ at random. Each of these $n$ households is sent for a pooled coronavirus test. We then use the number positive tests results in our sample to construct an estimate $E$ of the number of infected households in the population. For example, if 1 household in a sample of 300 tests positive, then we would estimate that 10 households out of 3000 in the university have coronavirus. Repeating this process weekly would allow us to estimate how the prevalence of coronavirus changes over time.

Because households are chosen at random, the estimated number of infected households $E$ may not equal the true number of infected households $C$. Purely by chance, we might draw a sample of households in which no one is infected. In this case $E$ would equal zero: an underestimate of $C$. We could also be unlucky in the opposite direction and, purely by chance, draw a sample that contains everyone at Oxford who is infected. In this case $E$ would be an overestimate of $C$. Both of these possibilities, however, are remote: $E$ is highly likely to be close to $C$. With an appropriate sample size, an estimate based on random testing is reliable enough to tell us with high confidence whether $C$ is, say, greater than 50 or fewer than 20. It can also be used to determine whether prevalence is increasing and, if so, how quickly. 

## Testing Symptomatic Individuals Does Not Suffice

Relative to the Early Alert Testing system, which tests only symptomatic individuals, a crucial advantage of randomized testing, or universal testing, is that it will also detect pre-symptomatic and asymptomatic cases. This is important because, as explained in the  [SAGE report of 3rd September](https://www.gov.uk/government/publications/principles-for-managing-sars-cov-2-transmission-associated-with-higher-education-3-september-2020), "asymptomatic transmission is a key risk in university settings." Indeed, a recent study cited in the SAGE report finds that only 18\% of those aged 0--19 and 22\% of those aged 20--39 who are infected with coronavirus show symptoms of the disease.[^2] Even if these figures are substantial overestimates, it is likely that a considerable fraction of infections among our students will go undetected by the Early Alert Testing system. While students themselves are at low risk of serious complications from coronavirus, members of staff are at substantially higher risk. By the time the Early Alert system registers an increase in cases among members of staff, it may already be too late for mitigation policies, such as curtailing in-person instruction, to be effective. Even if their turn-around times were somewhat slower than those for tests conducted through the Early Alert system, randomized pooled tests could still provide more timely information about the spread of infection, given the likely extent of asymptomatic transmission among our students.

[^2]: [https://arxiv.org/abs/2006.08471](https://arxiv.org/abs/2006.08471)


## How many samples are required?

The key question in designing a randomized testing protocol is how large a sample size to use. To answer this question, we first need a rough idea of the prevalence of coronavirus among households at the beginning of term. Based on recent results from [REACT-1](https://www.gov.uk/government/publications/react-1-study-of-coronavirus-transmission-august-2020-results/react-1-real-time-assessment-of-community-transmission-of-coronavirus-covid-19-in-august-2020), approximately 0.25\% of individuals in the 18-24 age group had the coronavirus at the start of September. Taking this as a lower bound for prevalence in early October, suppose that at least 45 of the roughly 18,000 students in residential accommodation has coronavirus at the start of MT. Given that our interest is in households rather than individuals, the question remains: if 45 students have coronavirus, then how many *households* are infected? 


```{r,echo = FALSE}
E_sick_HH <- function(N, k, S) {
  N * (1 - dhyper(0, S, k * N - S, k))
}
```

The answer depends on what we are willing to assume about households. At one extreme, as many as 45 households could be infected: this would require that exactly *one* person in each affected household has the coronavirus. At the other extreme, it is possible that as few as 8 households could be infected. This would require 7 households in which every member was infected, and 1 household with 3 infected members. During term, intra-household transmission will likely be substantial.[^intra] At the beginning of term, however, it is unlikely that cases will cluster strongly within households, as most groups will not have met in person over the summer. If initial coronavirus cases can be viewed as independently and uniformly assigned to households, then 45 infected students would translate into approximately `r round(E_sick_HH(3000, 6, 45), 1)` infected households on average.[^indep] To allow for some initial clustering of cases, lower this by a third and suppose that there are initially 35 infected households, yielding a household prevalence of approximately 1.16\% at the start of term.

[^intra]: A secondary infection rate of 38\% within households would be consistent with a recent study of patients in New York State: <https://doi.org/10.1093/cid/ciaa549>.

[^indep]: Specifically, if $N$ is the number of households, $k$ is household size, and $S$ is the number of infected students, the expected number of infected households is $N \left[1 -  \binom{kN - S}{k} / \binom{kN}{k} \right]$.

Given a rough idea of household prevalence at the start of MT, there are several simple ways to approximate the sample size required for randomized pooled testing to provide useful information. The first and simplest is to ask how many households we would need to test, on average, before obtaining our first positive result. If $C$ out of the 3000 households are infected at the start of term, then the answer is approximately 3000/$C$.[^exact] Table 1 provides exact results over a range of values for $C$. This calculation gives a rough-and-ready method for showing that a proposed sample size is likely *too small* to be useful. For example, a sample size of 50 households would be too small to provide useful information when $C$ is close to 35 because we would, on average, require approximately 83 samples to obtain our first positive result if this were the true number of infected households. 

[^exact]: The exact value is $(N+1)/(C + 1)$ for a population of size $N$ containing $C$ positives.

```{r,echo=FALSE}
N <- 3000 
cases <- c(25, 30, 35, 40, 45, 50)
prevalence <- round(100 * cases / N, 2)
n_tests <- round((N + 1) / (cases + 1))
foo <- as.data.frame(cbind(cases, prevalence, n_tests))
knitr::kable(foo, col.names = c('Infected Households ($C$)', 'Prevalence (%)', 'Expected #Samples'),
             caption = 'Expected number of samples before the first positive result under random sampling without replacement from a population of size 3000.')
```


```{r,echo=FALSE}
get_prob_E_range <- function(lower, upper, n, C, N = 3000) {
  L <- lower * n / N
  U <- upper * n / N
  sum(dhyper(L:U, C, N - C, n))
}
```

A more refined way to determine an appropriate sample size is by calculating *how close* the estimated number of infected households, $E$, will likely be to the true number of infected households, $C$, for a given sample size. Suppose, as before, that there are initially 35 infected households. With a sample size of $n = 300$ the estimated number of infected households will fall in the range $[20,60]$, inclusive, with approximately  `r round(100 * get_prob_E_range(lower = 20, upper = 60, n = 300, C = 35))`\% probability. Moreover, with this sample size there would be only a `r round(100 * get_prob_E_range(lower = 0, upper = 0, n = 300, C = 35))`\% chance of *failing* to detect any infected households.[^4] 

[^4]: The results in this paragraph are calculated from the quantiles of a Hypergeometric($N$, $C$, $n$) distribution where $N$ is the population size, $C$ is the number of positives in the population, and $n$ is the sample size. 

```{r echo = FALSE}
get_exact_power <- function(cv, n, C1, N = 3000) {
  1 - phyper(cv, C1, N - C1, n)
}
```

A third way of deciding how many samples are needed is by calculating the chance that we woulc be able to reliably distinguish between two different levels of coronavirus prevalence. Suppose that we started term with 35 infected households. If this number doubled to 70, with a sample size of $n = 300$ we would have approximately a `r round(100 * get_exact_power(cv = 5, n = 300, C1 = 70))`\% of detecting an increase, with high confidence. If the number of infected households trebled to 105, our chance of detecting an increase with 300 samples would rise to `r round(100 * get_exact_power(cv = 5, n = 300, C1 = 105))`\%.[^power]

[^power]: These values correspond to a power calculation based on Fisher's exact test for a Hypergeometric$(N, C, n)$ distribution where $N$ is the population size, $n$ is the sample size, and $C$ is the number of positives in the population. For $N = 3000$ and $n = 300$ a test of $H_0\colon C \leq 35$ versus $H_1\colon C > 35$ with a critical value of $5$ has size $\alpha$ = `r round(get_exact_power(5, 300, 35), 2)`. (Due to discreteness it is impossible to achieve a size of precisely 0.1). The power of this test is `r round(get_exact_power(5, 300, 70), 2)` against the alternative $C = 70$ and `r round(get_exact_power(5, 300, 105), 2)` against the alternative $C = 105$.

Broadly speaking, our calculations suggest that a simple random sample of approximately 300 household groups per week would provide a considerable amount of useful information. This would amount to 10\% of the number of tests required for weekly universal testing and 20\% of the number required for fortnightly universal testing.

## Finding Clusters with Adaptive Sampling
Thus far assumed we want to estimate prevalence and considered simplest possible sampling procedure: simple random sample.
May also want to try to find and isolate clusters of infection.
In fact a more sophisticated sampling design can achieve both goals simultaneously: adaptive cluster sampling.[^adapt]
Define "neighborhoods" of households between which transmission is particularly likely, e.g. residence halls.
If one household tests positive, immediately test the other households in its neighborhood.
Deviation from simple random sample is more complicated to analyze mathematically but blah blah blah very good blah blah.[^adapt]

[^adapt]: [Thompson, S.K. (1990), "Adaptive Cluster Sampling", *Journal of the American Statistical Association*, 85(412), pp. 1050-1059](https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1990.10474975). 

```{r,echo=FALSE}
get_false_positive <- function(prev, sens, spec) {
# everything is in %
  term1 <- (100 - spec) / sens
  term2 <- (100 - prev) / prev
  return(100 - 100 / (1 + term1 * term2))
}
```

## What about false positives and negatives?
Thus far we have abstracted away the problem of false positives and false negatives. As our primary goal is to estimate prevalence and identify clusters of infection rather than to diagnose particular individuals, this is not a major concern. First, if false positive and false negative rates are constant, we can still gain useful information by examining *changes* in estimated prevalence. Second, recent research has proposed estimates of these rates that can be used to correct estimates of population prevalence. 

**Moreover: false positives are most likely when prevalence is low. But prevalence among households is necessarily higher than that among individuals so pooling should help here. Give calculation. Then do some back of the envelope calculation assuming characteristics of pooled tests match those of individual tests. Point out that it's only a rough approx because it's based on individual tests. Presumably the false positive rate will not be very large.**

## Appendix: Approximating False Positive Rates

**Need to change this to refer to *households* and emphasize that we don't know for sure how the test characteristics translate to pooled testing so this is only a back-of-the-envelope calculation**

- Approximately `r round(get_false_positive(100 * 35/ 3000, 71, 99.96))`\% of tests at the household level will be false positives.
- If we lower the specificity to 99\% then around `r round(get_false_positive(100 * 35/ 3000, 71, 99))`\% are false positives. So the key is what the specificity is. If it were 99.9\% then `r round(get_false_positive(100 * 35/ 3000, 71, 99.9))`\% false positives
- But point out that this problem is also relevant for testing of symptomatic individuals! 
- For purposes of comparison, coronavirus prevalence among those showing symptoms of the disease was approximately 0.68\% at the beginning of September, according to REACT-1. Thus, under the present government policy of testing only symptomatic individuals, no more than `r round(get_false_positive(0.68, 71, 99.96))`\% positive tests will be false positives. 
- Note that a prevalence of 0.68\% among symptomatic individuals is *lower* than our conservative estimate of prevalence among *households* at the start of term. (This is because the only possibilities are 8-45 infected groups if you have 45 infected individuals)
- So the real question is whether the specificity[^pool]

[^pool]: <https://doi.org/10.1017/S0950268820001752>


The likelihood of a false positive depends on three factors: the *sensitivity* and *specificity* of a test along with the prevalence of coronavirus in the relevant population. Sensitivity is the share of people who test *positive* among those who *have coronavirus*. Estimates of the sensitivity of PCR tests vary, but range between 71\% and 98\%.[^10] Specificity is the share of people who test *negative* among those who *do not have coronavirus*. We can bound the specificity of PCR tests fairly accurately using results from the [ONS Infection survey pilot](https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/methodologies/covid19infectionsurveypilotmethodsandfurtherinformation). Between 1 June and 12 July, only 50 of the 122,776 samples collected as part of this survey tested positive. To compute a lower bound for the specificity, suppose that all 50 positive results were false positives. If true, this would mean that the ONS obtained 122,726 negative test results in a group of 122,776 people who did not in fact have coronavirus, implying a specificity of 99.96\%. If any of the positive test results were true positives, then the true specificity must be higher. To be conservative, assume a sensitivity of 71\% and a specificity of 99.96\%. According to [REACT-1](https://www.gov.uk/government/publications/react-1-study-of-coronavirus-transmission-august-2020-results/react-1-real-time-assessment-of-community-transmission-of-coronavirus-covid-19-in-august-2020), the prevalence of coronavirus in the population as a whole was approximately 0.13\% at the beginning of September. At this rate of prevalence, no more than `r round(get_false_positive(0.13, 71, 99.96))`\% of positive test results will be false positives.[^9] Among university-aged individuals, however, estimated prevalence was approximately 0.25\%. Thus, among students no more than `r round(get_false_positive(0.25, 71, 99.96))`\% of positives will be false positives. 

Whether this should be viewed as a high or low number, of course, depends on one's perspective. As explained above, a policy of testing only symptomatic individuals may miss up to 80\% of all coronavirus cases among our students. Under a policy of universal testing, on the other hand, up to 18\% of students instructed to self-isolate may have been inconvenienced unnecessarily.

[^9]: Defining $B = (100\% - \text{Specificity})\times (100\% - \text{Prevalence}) / (\text{Sensitivity} \times \text{Prevalence})$, the false positive rate is given by $[B/(1 + B)]$\%.
[^10]: <https://www.bmj.com/content/369/bmj.m1808>
